setwd("~/GitHub/ECR-GROUP-3")
knitr::opts_chunk$set(echo = TRUE)
#installing the packages
install.packages("stringdist")
#installing the packages
#install.packages("stringdist")
##call libraries##
library(dplyr)
library(ggplot2)
library(stringr)    # string operations
library(sf)         # spatial operations
#installing the packages
#install.packages("stringdist")
install.packages("sf")
#installing the packages
#install.packages("stringdist")
#install.packages("sf")
##call libraries##
library(dplyr)
library(ggplot2)
library(stringr)    # string operations
library(sf)         # spatial operations
library(readr)      # CSV I/O
library(scales)     # squish() for color capping
library(stringdist) # fuzzy matching
library(tidyverse)
#library(survey)
## load data file
data <- read_csv("data/DHS/DHS_ITN_person_data.csv")
## load data file
data <- read_csv("../data/DHS/DHS_ITN_person_data.csv")
getwd()
knitr::opts_chunk$set(echo = TRUE)
## load data file
data <- read_csv("data/DHS/DHS_ITN_person_data.csv")
## load data file
data <- read_csv("DHS/DHS_ITN_person_data.csv")
##call libraries##
library(dplyr)
library(ggplot2)
library(stringr)    # string operations
library(sf)         # spatial operations
library(readr)      # CSV I/O
library(scales)     # squish() for color capping
library(stringdist) # fuzzy matching
library(tidyverse)
library(survey)
##installing required libraries (option 1)##
install.packages("devtools")
devtools::install_github("ropensci/rdhs")
install.packages("devtools")
library(rdhs)
install.packages("survey")
if (!require("remotes")) install.packages("remotes")
remotes::install_github("ropensci/rdhs")
data6<- data %>%
select(country, admin1_dhs, admin1_name, dhsid, urban_rural,
clusterid, householdid,personid,netid,slept_under_net_types) %>%
mutate(across(netid, ~ replace_na(netid, 0))) %>%
mutate(has_ITN=ifelse(netid>0&
(slept_under_net_types=="treated and untreated nets"|slept_under_net_types=="treated nets"),1,0))%>%
group_by(householdid) %>%
mutate(across(has_ITN, ~ replace_na(has_ITN, 0))) %>%
mutate(HHmember_count=n_distinct(personid))%>%
filter(netid==max(netid))%>%
select(-c(personid))%>%
slice(1)
HH_data <- data6 %>%
mutate(
net_per_person = netid / HHmember_count)
### Create survey design with clusters only (no weights/strata)
svy_design <- svydesign(
ids = ~clusterid,      # Primary sampling unit (PSU)
strata = NULL,         # No stratification
weights = ~1,          # Equal weights (assume self-weighting)
data = HH_data,
nest = TRUE            # Handle nested households if applicable
)
##create ITN utilization
data_with_ITN_use<- data %>%
select(country, admin1_dhs, admin1_name, dhsid, urban_rural,
clusterid, householdid,personid,slept_under_net_types,sex,
slept_under_itn) %>%
mutate(itn_use =
ifelse(slept_under_itn == "yes",1,     # Yes
ifelse(slept_under_itn == "no", 0, NA)))
##creating ITN utilization variables
HH_ITN_utilization_variables<-data_with_ITN_use %>%
group_by(householdid) %>%
mutate(ITN_use_count=n_distinct(itn_use))%>%
mutate(HHmember_count=n_distinct(personid))%>%
select(-c(personid,sex,slept_under_net_types,slept_under_itn,itn_use))%>%
slice(1)
HH_with_ITN_utilization<-HH_ITN_utilization_variables %>%
mutate(ITN_utilization=ITN_use_count/HHmember_count)
write.csv(HH_with_ITN_utilization, "C:/Users/HP EliteBook/OneDrive/Desktop/Group 2/data/HH_with_ITN_utilization.csv", row.names = FALSE)
write.csv(HH_ITN_utilization_variables, "C:/Users/HP EliteBook/OneDrive/Desktop/Group 2/data/HH_ITN_utilization_variables.csv", row.names = FALSE)
write.csv(data_with_ITN_use, "C:/Users/HP EliteBook/OneDrive/Desktop/Group 2/data/data_with_ITN_use.csv", row.names = FALSE)
write.csv(HH_data, "C:/Users/HP EliteBook/OneDrive/Desktop/Group 2/data/HH_data.csv", row.names = FALSE)
write.csv(data6, "C:/Users/HP EliteBook/OneDrive/Desktop/Group 2/data/data6.csv", row.names = FALSE)
HH_data <- data6 %>%
mutate(
net_per_person = netid / HHmember_count)
### Create survey design with clusters only (no weights/strata)
svy_design <- svydesign(
ids = ~clusterid,      # Primary sampling unit (PSU)
strata = NULL,         # No stratification
weights = ~1,          # Equal weights (assume self-weighting)
data = HH_data,
nest = TRUE            # Handle nested households if applicable
)
##create ITN utilization
data_with_ITN_use<- data %>%
select(country, admin1_dhs, admin1_name, dhsid, urban_rural,
clusterid, householdid,personid,slept_under_net_types,sex,
slept_under_itn) %>%
mutate(itn_use =
ifelse(slept_under_itn == "yes",1,     # Yes
ifelse(slept_under_itn == "no", 0, NA)))
##creating ITN utilization variables
HH_ITN_utilization_variables<-data_with_ITN_use %>%
group_by(householdid) %>%
mutate(ITN_use_count=n_distinct(itn_use))%>%
mutate(HHmember_count=n_distinct(personid))%>%
select(-c(personid,sex,slept_under_net_types,slept_under_itn,itn_use))%>%
slice(1)
HH_with_ITN_utilization<-HH_ITN_utilization_variables %>%
mutate(ITN_utilization=ITN_use_count/HHmember_count)
##installing required libraries (option 1)##
install.packages("devtools")
install.packages("devtools")
# ── 0. Packages ─────────────────────────────────────────────────────────────
library(dplyr)      # data wrangling
library(stringr)    # string operations
library(sf)         # spatial operations
library(readr)      # CSV I/O
library(ggplot2)    # plotting
library(scales)     # squish() for color capping
library(stringdist) # fuzzy matching
# ── 9. QC-map: crop stray points & draw final map ───────────────────────────
admin2_map   <- admin2_sf %>%
dplyr::left_join(admin2_panel,
by = c("country","admin2_name","admin1_name"))
admin2_union <- sf::st_union(admin2_sf)
# ── 9a. Prepare cluster points for overlay ─────────────────────────────────
cluster_pts <- cluster_sf2 %>%
# we only want points that found a district
dplyr::filter(!is.na(admin2_name)) %>%
# and crop any strays outside the union of all Admin2 polygons
sf::st_filter(admin2_union)
# ── 9b. Plot ────────────────────────────────────────────────────────────────
ggplot() +
geom_sf(
data   = admin2_map,
aes(fill = prop_use),
colour = "grey50", size = 0.1
) +
geom_sf(
data   = cluster_pts,
colour = "black", size = 0.4, alpha = 0.6
) +
coord_sf() +
scale_fill_viridis_c(
option   = "viridis",
na.value = "lightgrey",
limits   = c(0, 0.9),
oob      = scales::squish,
name     = "ITN use\nproportion"
) +
labs(
title    = "District‐level ITN use and survey clusters",
subtitle = "All Zambia & Tanzania surveys combined"
) +
theme_void(base_size = 14) +
theme(
plot.title    = element_text(face = "bold", size = 16, hjust = 0.5),
plot.subtitle = element_text(size = 12, hjust = 0.5),
legend.title  = element_text(size = 12),
legend.text   = element_text(size = 10)
)
# ── 9b. Plot ────────────────────────────────────────────────────────────────
ggplot() +
geom_sf(
data   = admin2_map,
aes(fill = prop_use),
colour = "grey50", size = 0.1
) +
geom_sf(
data   = cluster_pts,
colour = "black", size = 0.4, alpha = 0.6
) +
coord_sf() +
scale_fill_viridis_c(
option   = "viridis",
na.value = "lightgrey",
limits   = c(0, 0.9),
oob      = scales::squish,
name     = "ITN use\nproportion"
) +
labs(
title    = "District‐level ITN use and survey clusters",
subtitle = "All Zambia & Tanzania surveys combined"
) +
theme_void(base_size = 14) +
theme(
plot.title    = element_text(face = "bold", size = 16, hjust = 0.5),
plot.subtitle = element_text(size = 12, hjust = 0.5),
legend.title  = element_text(size = 12),
legend.text   = element_text(size = 10)
)
# ── 9. QC-map: crop stray points & draw final map ───────────────────────────
admin2_map   <- admin2_sf %>%
dplyr::left_join(admin2_panel,
by = c("country","admin2_name","admin1_name"))
admin2_union <- sf::st_union(admin2_sf)
# ── 9a. Prepare cluster points for overlay ─────────────────────────────────
cluster_pts <- cluster_sf2 %>%
# we only want points that found a district
dplyr::filter(!is.na(admin2_name)) %>%
# and crop any strays outside the union of all Admin2 polygons
sf::st_filter(admin2_union)
# ── 9b. Plot ────────────────────────────────────────────────────────────────
ggplot() +
geom_sf(
data   = admin2_map,
aes(fill = prop_use),
colour = "grey50", size = 0.1
) +
geom_sf(
data   = cluster_pts,
colour = "black", size = 0.4, alpha = 0.6
) +
coord_sf() +
scale_fill_viridis_c(
option   = "viridis",
na.value = "lightgrey",
limits   = c(0, 0.9),
oob      = scales::squish,
name     = "ITN use\nproportion"
) +
labs(
title    = "District‐level ITN use and survey clusters",
subtitle = "All Zambia & Tanzania surveys combined"
) +
theme_void(base_size = 14) +
theme(
plot.title    = element_text(face = "bold", size = 16, hjust = 0.5),
plot.subtitle = element_text(size = 12, hjust = 0.5),
legend.title  = element_text(size = 12),
legend.text   = element_text(size = 10)
)
# ── A. Packages ─────────────────────────────────────────────────────────────
library(malariaAtlas)   # getRaster()
library(raster)         # raster I/O & projection
library(exactextractr)  # exact_extract()
# 3. Pf parasite rate (2022)
pfpr <- getRaster(
surface = "Malaria__202206_Global_Pf_Parasite_Rate",
year    = 2022,
shape   = admin2_map
)
# ── D. Ensure all share CRS EPSG:4326 ───────────────────────────────────────
for(r in list(itn_access, tt_health, pfpr)) {
if(!compareCRS(r, admin2_map)) {
r <- projectRaster(r, crs = st_crs(admin2_map)$proj4string)
}
}
# ── E. Summarise each raster over polygons ─────────────────────────────────
# Note - sometimes you want the mean, sometimes the total when working with covariates - have a think!
admin2_map <- admin2_map %>%
mutate(
mean_itn_access   = exact_extract(itn_access,   geometry, 'mean'),
mean_tt_health    = exact_extract(tt_health,    geometry, 'mean'),
mean_pfpr         = exact_extract(pfpr,         geometry, 'mean')
)
# ── F. Inspect & merge into your panel ─────────────────────────────────────
admin2_panel <- readr::read_csv("/mnt/data/admin2_ITN_panel.csv") %>%
left_join(
admin2_map %>%
st_drop_geometry() %>%
select(country, admin1_name, admin2_name,
mean_itn_access, mean_tt_health, mean_pfpr),
by = c("country","admin1_name","admin2_name")
)
# ── G. Export enriched panel ────────────────────────────────────────────────
readr::write_csv(
admin2_panel,
"data/admin2_ITN_panel_with_MAP_covariates.csv"
)
Agregated<-read.csv("~/B_Analysis_Folder/ECR-GROUP-3/data/DHS/DHS_ITN_admin2_aggregated.csv")
# Basic logistic regression is done with base R's glm()
# But tidy summaries need broom or finalfit
install.packages("broom")    # Optional: for tidy output
library(broom)
#####Value label######
Agregated$n_slept_under_net<- factor(Agregated$n_slept_under_net, levels = c(0, 1), labels = c("No", "Yes"))
Agregated<-read.csv("~/B_Analysis_Folder/ECR-GROUP-3/data/DHS/DHS_ITN_admin2_aggregated.csv")
Agregated<-read.csv(Agregated<-read.csv("~/B_Analysis_Folder/ECR-GROUP-3/data/DHS/DHS_ITN_admin2_aggregated.csv")
# Basic logistic regression is done with base R's glm()
# But tidy summaries need broom or finalfit
install.packages("broom")    # Optional: for tidy output
# Basic logistic regression is done with base R's glm()
# But tidy summaries need broom or finalfit
install.packages("broom")    # Optional: for tidy output
install.packages("broom")
#######################################3
Ag<-read.csv("C:/Users/HP-ENVY/Documents/B_Analysis_Folder/ECR-GROUP-3/data/DHS/DHS_ITN_person_data.csv")
# Basic logistic regression is done with base R's glm()
# But tidy summaries need broom or finalfit
install.packages("broom")    # Optional: for tidy output
install.packages("broom")
library(broom)
#####Value label######
Ag$slept_under_itn<- factor(Ag$slept_under_itn, levels = c(0, 1), labels = c("No", "Yes"))
Ag$sex<- factor(Ag$sex, levels = c(1, 2), labels = c("Female", "Male"))
Ag$slept_under_ever_treated<- factor(Ag$slept_under_ever_treated, levels = c(0, 1), labels = c("No", "Yes"))
Ag$slept_under_net<- factor(Ag$slept_under_itn, levels = c(0, 1), labels = c("No", "Yes"))
View(Ag)
# Run multivariable logistic regression
Ag model <- glm(slept_under_itn ~  + sex + age + slept_under_ever_treated data + slept_under_net +
# Run multivariable logistic regression
Bi_model <- glm(slept_under_itn ~  + sex + age + slept_under_ever_treated data + slept_under_net +
# Run multivariable logistic regression
Bi_model <- glm(slept_under_itn ~ sex + age + slept_under_ever_treated data + slept_under_net +
# Run multivariable logistic regression
Bi_model <- glm(slept_under_itn ~ sex + age + slept_under_ever_treated + slept_under_net,
data = Dm,
family = "binomial")
# Run multivariable logistic regression
Bi_model <- glm(slept_under_itn ~ sex + age + slept_under_ever_treated + slept_under_net,
data = Ag,
family = "binomial")
# Tidy version
tidy(model, exponentiate = TRUE, conf.int = TRUE)  # Gives odds ratios and confidence intervals
table(Ag$sex)
table(Ag$slept_under_ever_treated)
table(Ag$slept_under_net)
table(Ag$slept_under_itn)
Ag$slept_under_net<- factor(Ag$slept_under_itn, levels = c(0, 1), labels = c("No", "Yes"))
# Run multivariable logistic regression
Bi_model <- glm(slept_under_itn ~ sex + age + slept_under_ever_treated + slept_under_net,
data = Ag,
family = "binomial")
# Run multivariable logistic regression
Bi_model <- glm(slept_under_itn ~ sex + age + slept_under_ever_treated +
data = Ag,
# Run multivariable logistic regression
Bi_model <- glm(slept_under_itn ~ sex + age + slept_under_ever_treated
data = Ag,
# Run multivariable logistic regression
Bi_model <- glm(slept_under_itn ~ sex + age + slept_under_ever_treated,
data = Ag,
family = "binomial")
# View summary
summary(model)
# View summary
summary(Bi_model)
####Converting the coefficients to log odds###################
# 95% Confidence intervals for odds ratios
exp(confint(Bi_model))
# Fast, Wald-based odds ratios with confidence intervals
exp(cbind(OR = coef(Bi_model), confint.default(Bi_model)))
# Tidy version
tidy(model, exponentiate = TRUE, conf.int = TRUE)  # Gives odds ratios and confidence intervals
table(Ag$sex)
table(Ag$slept_under_ever_treated)
View(Ag)
Ag$slept_under_llin<-factor(Ag$slept_under_llin, levels = c(0, 1), labels = c("No", "Yes"))
# Run multivariable logistic regression
Bi_model <- glm(slept_under_itn ~ sex + age + slept_under_ever_treated + slept_under_llin,
data = Ag,
family = "binomial")
# View summary
summary(Bi_model)
# Fast, Wald-based odds ratios with confidence intervals
exp(cbind(OR = coef(Bi_model), confint.default(Bi_model)))
